{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eec4df6-e74e-45f6-9f5b-60fcd4c5e15d",
   "metadata": {},
   "source": [
    "# **Preprocessing**\n",
    "* Container: codna_pytorch_p310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd271a-31c2-480f-9d6d-a3ab86b05be4",
   "metadata": {},
   "source": [
    "## AutoReload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adea942a-4491-4176-bc23-d2aa295569d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b5951-4956-4bb5-8e4d-a754c639946f",
   "metadata": {},
   "source": [
    "## 1. Processing-job for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbb8994-95a2-4795-bd7e-3abb682728bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, FrameworkProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f5af69-f86f-4508-9cb5-41df98fa9145",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## 2. parameter store 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e61a6f-7eca-4535-ad09-22304ba42460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.ssm import parameter_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b792f243-14d1-4e8e-b7c0-fc6e0fbfb63d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region=boto3.Session().region_name\n",
    "pm = parameter_store(region)\n",
    "prefix = pm.get_params(key=\"PREFIX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe874a86-81c5-44c9-9d89-5f87c2ca51b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Params for processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961cfb2a-da6a-4a38-a36f-3b961e9c53d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance-type: ml.m5.xlarge\n",
      "role: AmazonSageMaker-ExecutionRole-20221004T162466\n",
      "bucket: sm-bert-ramp\n",
      "dataset-path: s3://sm-bert-ramp/ramp-mlops/data/amazon_polarity.csv\n",
      "sagemaker_session: <sagemaker.session.Session object at 0x7f6fd50979a0>\n",
      "git_config: {'repo': 'https://git-codecommit.ap-northeast-2.amazonaws.com/v1/repos/bert-code', 'branch': 'main', 'username': 'dongjin-at-419974056037', 'password': 'n1h2OES6ZiHws5kGNt0TJxtoLaAGxjLkOxtmlzc5YWg='}\n"
     ]
    }
   ],
   "source": [
    "local_mode = False\n",
    "\n",
    "if local_mode: \n",
    "    instance_type = 'local'\n",
    "    \n",
    "    import os\n",
    "    from sagemaker.local import LocalSession\n",
    "    \n",
    "    sagemaker_session = LocalSession()\n",
    "    data_path = os.path.join(os.getcwd(), \"data\")\n",
    "    \n",
    "else:\n",
    "    instance_type = \"ml.m5.xlarge\" ## \"ml.g4dn.xlarge\"\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    data_path = pm.get_params(key=\"-\".join([prefix, \"DATA-PATH-S3\"]))\n",
    "    \n",
    "git_config = {\n",
    "    'repo': f'https://{pm.get_params(key=\"-\".join([prefix, \"CODE_REPO\"]))}',\n",
    "    'branch': 'main',\n",
    "    'username': pm.get_params(key=\"-\".join([prefix, \"CODECOMMIT-USERNAME\"]), enc=True),\n",
    "    'password': pm.get_params(key=\"-\".join([prefix, \"CODECOMMIT-PWD\"]), enc=True)\n",
    "}\n",
    "\n",
    "role = pm.get_params(key=\"-\".join([prefix, \"SAGEMAKER-ROLE-ARN\"]))\n",
    "bucket_name = pm.get_params(key=\"-\".join([prefix, \"BUCKET-NAME\"]))\n",
    "    \n",
    "print (f'instance-type: {instance_type}')\n",
    "print (f'role: {role}')\n",
    "print (f'bucket: {bucket_name}')\n",
    "print (f'dataset-path: {data_path}')\n",
    "print (f'sagemaker_session: {sagemaker_session}')\n",
    "print (f'git_config: {git_config}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e70ed-de4a-46a2-b613-10af8837fbaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Define processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b07e5c-4522-4fcd-85c0-ce227b032f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_processor = FrameworkProcessor(\n",
    "    estimator_cls=PyTorch,\n",
    "    framework_version=\"2.0.0\",\n",
    "    py_version='py310',\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    base_job_name=\"preprocessing\", # bucket에 보이는 이름 (pipeline으로 묶으면 pipeline에서 정의한 이름으로 bucket에 보임)\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "proc_prefix = \"/opt/ml/processing\"\n",
    "\n",
    "output_path = os.path.join(\n",
    "    \"s3://{}\".format(bucket_name),\n",
    "    prefix,\n",
    "    \"preprocessing\",\n",
    "    \"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7587c7fe-8daf-489c-b977-08c3aa3fdf87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/tmp/tmp44p0e45c'...\n",
      "remote: Counting objects: 9, done.        \n",
      "Already on 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name preprocessing-2023-08-07-05-35-48-202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\u001b[34mWARNING: Skipping typing as it is not installed.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting accelerate>=0.20.3 (from -r requirements.txt (line 1))\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 244.2/244.2 kB 11.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.31.0 (from -r requirements.txt (line 2))\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.4/7.4 MB 40.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting datasets[s3]==1.18.4 (from -r requirements.txt (line 3))\n",
      "  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 312.1/312.1 kB 45.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (3.12.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.31.0->-r requirements.txt (line 2))\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 43.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers==4.31.0->-r requirements.txt (line 2))\n",
      "  Downloading regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 770.4/770.4 kB 60.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0->-r requirements.txt (line 2))\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 88.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.1 (from transformers==4.31.0->-r requirements.txt (line 2))\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 84.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 2)) (4.64.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets[s3]==1.18.4->-r requirements.txt (line 3)) (12.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets[s3]==1.18.4->-r requirements.txt (line 3)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets[s3]==1.18.4->-r requirements.txt (line 3)) (2.0.1)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from datasets[s3]==1.18.4->-r requirements.txt (line 3))\n",
      "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 41.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets[s3]==1.18.4->-r requirements.txt (line 3)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets[s3]==1.18.4->-r requirements.txt (line 3)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp (from datasets[s3]==1.18.4->-r requirements.txt (line 3))\n",
      "  Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 80.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting responses<0.19 (from datasets[s3]==1.18.4->-r requirements.txt (line 3))\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from datasets[s3]==1.18.4->-r requirements.txt (line 3)) (1.26.132)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore in /opt/conda/lib/python3.10/site-packages (from datasets[s3]==1.18.4->-r requirements.txt (line 3)) (1.29.132)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3fs in /opt/conda/lib/python3.10/site-packages (from datasets[s3]==1.18.4->-r requirements.txt (line 3)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->-r requirements.txt (line 1)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->-r requirements.txt (line 1)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[s3]==1.18.4->-r requirements.txt (line 3)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[s3]==1.18.4->-r requirements.txt (line 3)) (2.1.1)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5 (from aiohttp->datasets[s3]==1.18.4->-r requirements.txt (line 3))\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 25.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets[s3]==1.18.4->-r requirements.txt (line 3))\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0 (from aiohttp->datasets[s3]==1.18.4->-r requirements.txt (line 3))\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 41.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1 (from aiohttp->datasets[s3]==1.18.4->-r requirements.txt (line 3))\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.7/225.7 kB 36.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2 (from aiohttp->datasets[s3]==1.18.4->-r requirements.txt (line 3))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->-r requirements.txt (line 2)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 2)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 2)) (1.26.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 2)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.20.3->-r requirements.txt (line 1)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.20.3->-r requirements.txt (line 1)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.20.3->-r requirements.txt (line 1)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->datasets[s3]==1.18.4->-r requirements.txt (line 3)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->datasets[s3]==1.18.4->-r requirements.txt (line 3)) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore->datasets[s3]==1.18.4->-r requirements.txt (line 3)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[s3]==1.18.4->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[s3]==1.18.4->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore->datasets[s3]==1.18.4->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.20.3->-r requirements.txt (line 1)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.20.3->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, safetensors, xxhash, regex, multidict, frozenlist, async-timeout, yarl, responses, huggingface-hub, aiosignal, transformers, aiohttp, accelerate, datasets\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.19.0\n",
      "    Uninstalling accelerate-0.19.0:\n",
      "      Successfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.21.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.2 datasets-1.18.4 frozenlist-1.4.0 huggingface-hub-0.16.4 multidict-6.0.4 regex-2023.6.3 responses-0.18.0 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0 xxhash-3.3.0 yarl-1.9.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.2.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mReceived arguments Namespace(proc_prefix='/opt/ml/processing', split_rate='0.8')\u001b[0m\n",
      "\u001b[34m#015Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]#015Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 181kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]#015Downloading (…)lve/main/config.json: 100%|██████████| 483/483 [00:00<00:00, 3.14MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 73.5MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]#015Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.35MB/s]#015Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.34MB/s]\u001b[0m\n",
      "\u001b[34mtrain: (8000, 3), test: (2000, 3)\u001b[0m\n",
      "\u001b[34mParameter 'function'=<function preprocess.tokenize at 0x7f34b04feb90> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?ba/s]#015100%|██████████| 1/1 [00:01<00:00,  1.74s/ba]#015100%|██████████| 1/1 [00:01<00:00,  1.74s/ba]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?ba/s]#015100%|██████████| 1/1 [00:00<00:00,  2.41ba/s]#015100%|██████████| 1/1 [00:00<00:00,  2.41ba/s]\u001b[0m\n",
      "\u001b[34mInMemoryTable\u001b[0m\n",
      "\u001b[34mlabels: int64\u001b[0m\n",
      "\u001b[34mtitle: string\u001b[0m\n",
      "\u001b[34mcontent: string\u001b[0m\n",
      "\u001b[34minput_ids: list<item: int32>\n",
      "  child 0, item: int32\u001b[0m\n",
      "\u001b[34mattention_mask: list<item: int8>\n",
      "  child 0, item: int8\u001b[0m\n",
      "\u001b[34m----\u001b[0m\n",
      "\u001b[34mlabels: [[0,1,1,0,0,...,1,0,0,0,1],[0,0,0,0,1,...,0,0,0,1,1],...,[1,0,1,1,1,...,0,0,0,1,0],[0,1,0,1,0,...,1,1,0,0,0]]\u001b[0m\n",
      "\u001b[34mtitle: [[\"Terrible!\",\"Can't put down\",\"Short, fun, sharp\",\"I DON'T KNOW WHAT THE WRITER WAS THINKING!\",\"It just doesn't sound right.\",...,\"The best, from boiled eggs to holiday feasts\",\"WARNING! KEEP AWAY FROM THE AUDIO VERSION!!!!\",\"High shipping charges\",\"bad service! Wrong product listing vs.. what you receive\",\"Don't believe the review above.\"],[\"Incredibly Unreliable\",\"What's all the Hype about? This movie bites!\",\"Funny Parts--Lame Overall\",\"sadly, I am not impressed\",\"Brilliant\",...,\"A WASTE OF TIME\",\"Absolutely awful!\",\"Not happy\",\"Maglite 4D purchase\",\"littlepig\"],...,[\"Kinda like watching poker on TV only in book form.\",\"The Last World\",\"Good old Rock\",\"finally!\",\"Great Music, Crummy Packaging\",...,\"Don't make my mistake, buy Linksys instead!\",\"Evil\",\"Jump!\",\"Fabulous cover tunes\",\"missing?\"],[\"A very disappointing read.\",\"WE LOVE THIS MUSIC\",\"Tight waistband\",\"Bound by Love\",\"0 star product, 5 star service\",...,\"Awesomeness!\",\"Star celebrates Girls Night Out\",\"Don't waste your money!!\",\"few japanese/okinawan karate masters, too much US\",\"Didn't last\"]]\u001b[0m\n",
      "\u001b[34mcontent: [[\"Not only is Jillian annoying she has no idea what she is doing! Total waste of money, time and patience!\",\"I picked this up last night and couldn't put it down. Not only that, but after each chapter I just stopped and thought for a minute or two. Just incredible.Get it and read it.\",\"Evan Mandery's first novel wears its debt to Vonnegut on its sleeve, but there's something else going on as well. Mandery digs into the loneliness of being gifted in a funny way. Mandery sees the best minds of his generation working[...]jobs for short pay and nourishing impossible dreams of celebrity, clinging to an untenable illusion in order to not be completely disillusioned. His protagonist is too good for this world, and somehow not good enough. I think he rather overstates his deterministic worldview, which is logically flawed-- why is it so important to not be animal? Why would it be psychologically crucial that the differences between man and animal be qualitative rather than quantitative? But this isn't a work of philosophy, and the flaws in Mandery's thinking illuminate his protagonist-- their voices and issues overlap considerably, which is usual in a first novel. I expect Mandery's voice to develop and become more assured and more Mandery in his next novel!\",\"Good comedy should have a strong sense of reality. After all, laughter is a release of frustrations and pain that takes place in your real life. This movie just is not realistic. Ellen is great, and the film could have been good if it kept to realism. That altar scene is one example. Half way thru, I lost interest. Save your money!\",\"On paper this CD looks like a can't miss. But while Siobhan De Mare's vocals were perfectly matched to the retro trip-hop of Mono's \"Formica Blues\", they sound strangely awkward here. Robin Guthrie's music is pure Cocteau Twins, and maybe that's part of the problem. After the first few notes you just can't wait to here Elizabeth Fraser's unique brand of gibberish floating dreamily over the ambient waves. But here, de Mare attacks and ultimately overwhelms the songs. It's grating to the ears and sadly unenjoyable.\",...,\"This book is a must in every kitchen. I consider myself to be a fairly accomplished cook, and I'm not afraid to try new and complicated recipes in the latest cookbooks. Fannie Farmer, however, is my *ANCHOR* cookbook. I always go back to this cookbook when I'm thinking of modifying or combining other recipes, because Fannie is packed with basic tips and procedures for making sauces, roasting, baking, proofing dough, and so on. This book will tell you the best way to bake a potato, roast chestnuts, and roll out pie-crust. It offers lots of variations, substitutions, and so on for 1000's of recipes that constitute the basics of today's American cooking (including the influence of world cuisines). I've given this cookbook to several younger friends as bridal shower gifts. It's the best start to your kitchen library!\",\"Holy Moley!! Blair is the narrator of the audio version of his book. He speaks in such a passionless, monotone voice that you run the risk of falling asleep while listening to it in your car. James Earl Jones he's not.\",\"My comments are the same as other customer / reviewer - the item is $2 and shipping is $10. Product is fine, but to have a shipping charge of 5 times the retail cost seems silly.\",\"I ordered the floaters and got dispeners! Don't ask for a replacement because they send the wrong item a second time.\",\"This game is great. The review above doesn't do it any justice whatsoever. If you are thinking of not buying it because of this, don't. Buy it, it is a great game. The visuals make the puzzles more fun, and while the difficulty of moving a mouse is a problem, we all already know the story. We have it for the visuals. There is no excuse for Myst fans not to have this game.\"],[\"The specs look very good, so I bought my first of these on the recommendation of a friend who had one that had worked for several months. After a few months, mine began measuring intermittently - sometimes it was correct, sometimes it only registered 1/2 the actual rainfall.Since my friend's unit was still working fine, I figured mine was a fluke and bought another one. This one worked for two months and then reported that it had lost the transmitter signal. I could not make it work reliably at any distance - and not at all if the receiver was more than 3 feet from the gauge.I have since learned that my friend's unit quit working with the same symptoms. That's strike 3. I'd say that 0 for 3 is a really lousy record for LaCrosse QC.\",\"I can't believe all the hype this movie has gotten. Aside from the fact that its is filmed inside of one room with different lighting, it fails to entertain. Perhaps its the one dimensional characters that we are supposed to mentally deconstruct. The acting was horrible. A fifth grade drama class could have done better.\",\"I adore Jack Nicholson, and that's why I went to see this movie. I doubt I'd given it a second thought had he not been in it, because I'm not a big Adam Sandler fan. (Sandler was surprisingly not obnoxious, as he tends to be.)I laughed quite a few times. There definitely were entertaining parts of the movie. However, the storyline was incredibly stupid. I wanted to like it so much, but I walked out of the cinema thinking \"What is Jack Nicholson doing in a lame movie like that?!\"\",\"Ditto. I am not impressed. This is an OK coffee, but no more than that, while, say, Davidoff Coffee that Amazon sells also, being much superior, excells in taste in quality... I am a Davidoff fan now. Never again, Mount Hagen! Get lost!\",\"What a magnificent poet. To hear his voice is just like traveling back in time. The wisdom is astounding.\",...,\"My eight year old spent about 10 minutes with this and walked away.No educational value at all. Just press in the right position to flip the spiderman. How many times does a child want to do that?\",\"The packaging of this DVD is very misleading. I assumed I was buying a series by the renowned Discovery Channel. This is a cheap knockoff. The video is horrible and the english translating is worse. Don't waste your money!\",\"This pan is too flimsy. During first use when I tried to sear meat in it on the stove top on med-high heat before putting in the oven, the pan burned and buckled, and it did not brown the meat.\",\"I was very happy with the order. Everything happened as expected with no surprises. The order arrived on time and the notification from Amazon and the vendor sending the item were all very good and timely. I would definitly go through Amazon again for future items and recommend Amazon to friends and family.\",\"This is a seriously comprehensive book of the Spear family that is descent from George Spear in the 1600's. If you know for a fact that it is George Spear who is your immigrant ancestor, and you are pursuing your Spear ancestry back to him, just buy this book. I wasted a lot of time and money with other books and did so much research, just to find it all in this book. I am so happy to have found it.\"],...,[\"If you like watching poker tournaments on TV then I think you will like this book. I read Phil Gordon's Little Green Book and really liked the segments where he described actual hands that he had played in the past and how they turned out, good or bad. I actually wanted more of that and this book is exactly that, more play by play action. I like the format and the way he gives you the opportunity to think about what you would do given the information he had at each turn of the hand. It is sort of like a practice book for what you may have learned in the Little Green Book. I definitely think you need to read the Green Book first.\",\"At best this is a \"fair\" read. For anyone with some military experience it is even less so. The characters tend to be stereotypical and not realistic in most cases. The plot \"twists\" are obvious from early on and don't really twist that much. What I found most frustrating was that the author didn't take the 20 seconds needed to do some simple research in various areas. For example, Tornados (or any aircraft) would not attack a ground target with Sidewinder missiles since they are air-to-air missiles. Such sloppiness in details is apparent throughout the book.If you get frustrated with people who try to demonstrate their knowledge of a particular area and then wind up showing you how little they really do know, you will want to throw this book against the wall at various times.If you are looking for something to pass boring hours in the airport this book may just keep you mildly entertained.\",\"I bought this album in the mid 70's and loved it then. still love it. It is one of bob's best albums. it is a great live album. If you like Bob Seger then this is a must have.\",\"This is the best my wife and I have found. I feels \"natural\", it's thick enough, and it's slippery but not too slippery and best of all it dosent't seem to get sticky! The only problem for us was finding it consistantly--- no place local stocks it.\",\"As the owner of several discs in the Oldies But Goodies series for quite a number of years, I recently ordered an additional six discs to \"fill in the holes\" in my collection. Much to my dismay, all arrived packaged in flimsy, cardboard \"albums\", rather than the substantial jewel cases used for my earlier purchases. In addition, some of the color combinations used on the packages (gold on red/gold on purple) make it nearly impossible to read the artists names without holding the package under a lamp.Try as I might, I was unable to find any information in the product details that mentioned the type of packaging. I intend to handle and play these discs for years, not just rip the songs to mp3's and load them on a hand-held player.In the interest of full-disclosure, and to improve customer satisfaction, I believe Amazon should include product packaging information.\",...,\"Buy a Linksys router instead! The D-Link product concept is good. A wireless router with a print server built in. I can hard wire my PC for broadband at my desk, as well as use my laptop anywhere in or outside the house . With this set up, I can surf the net with both computers at the same time with one internet connection. The plus is that I can also use the printer with both computers. The problem is that I have been unable to connect to the internet with this router! Tech support is clueless as to the problem. I have spent several days on the phone trying different scenerios without luck.The concept is great, but the equiptment is useless.Buy LINKSY, great equiptment, ran flawlessly and great tech support.\",\"This book was so evil I couldn't sleep for days after I read it (without exaggeration). I had bad dreams and I had bad during-the-day experiences(which is very unusual for me).I don't like that I find myself in the position of giving a book such a terrible review, but I also don't like the idea of not offering a warning to people, \"Don't open this door.\"BTW: The author even went so far as to suggest introducing your \"victim\" to the occult as a means of hooking and keeping your prey.\",\"I paid good money for this book so I've been trying hard to finish it these last couple of weeks. Hornby hasn't made it easy though. Lacking any of the charm found in his first book High Fidelity, this ponderous piece of garbage may well be one of the first books I have flung out the window in a long, long time. Such a shame too...High Fidelity, About A Boy...fine little reads..Too bad his last two efforts have been such stinkers, this one in particular. One star only because I know the guy can write. You would never know it , however, if this was the first book of his you had bought.\",\"All the songs on this cd are wonderful reproductions with the Braun flair. Only reason I gave it 4 stars instead of 5 is because it is too short. Great job, Rick!\",\"Thsi cd is missing \"6 underground\" by The Sneaker Pimps, \"Mandy\" by Barry Manilow and \"Get It On\" By Kingdome Come (the song in the background when they show the nerds getting on the roof and William leaving and then they pan into the party...great tune.I can do without worthless ... pop punk like anything by Blink 182 and I am sick and tired of everything by Smashmouth.\"],[\"I have read many books by this author and I am very disappointed in this last one. The plot was stupid and the characters were stupid. If you must read this book then borrow it so you will have the money for a good book later.\",\"Our baby absolutely loves this cd. In fact, we listen to it a few times a day. She loves listening to it before bedtime and in the car. One time she was screaming so loud and I put the CD in the CD player in she instantaneously calmed down. She was relaxed in a matter of seconds. If you are in need of a delightful, calming and soothing CD then you must get this. I really enjoy listening to it myself!! It's one of the best baby CD's that's come a long in a long time. I look foward to many more products from this company.\",\"Comfortable panty as far as fabric is concerned, but waistband runs tight. I also ordered a different size for my daughter, and she had the same experience with the waistband.\",\"This is one of my favorite books! It is so interesting to follow the Gutenberg Bible through the ages. Really neat concept that ties these four stories together.\",\"ZERO star product, forced to give it 1. Decided to start reusing a trackball that was used up until a year ago, and could not find my old adapter. So I ordered one from Amazon. did not work in 5 USB ports in 3 computers [including the one the trackball was originally attached to], so I tried with 3 other PS/2 devices, light came on in one of the mice when the adapter was inserted 1/4 the way, but when pushed in, NADA.Contacted Amazon, and Voila, a replacement was on its way. Just received the replacement, and get the same results. Last product from cables unlimited that I will purchase.Only positive is Amazon. Fast, efficient, customer oriented service. 5 ***** stars.\",...,\"I purchased one of these for myself along time ago and used it for years. Absolutely an awesome kitchen tool. I press and twist on the meat and it breaks it apart perfectly for chili, spaghetti, & soups. Highly recommend.\",\"If you enjoy a fast, funny, smart, how-to book, then Shine is perfect. Star celebrates the joy of finding happiness in the moment. Star celebrates her relationship with God and lives the scripture to 'eat, drink and be merry';for this is a gift from God. Thanks for the reminder Star.\",\"I received this as a christmas present 2005. I used it ONCE and the plastic base got hot and it started smelling like it was going to explode and then it just stopped working while I was mixing smoothies. I took it back the next day and exchanged it for another one. THE SAME THING HAPPENED AGAIN!! I am returning this horrible product!!\",\"This book provides little information about japanese and okinawan karate masters and is much to US oriented for a real encyclopedia.\",\"After only a month-and-a-half of relatively light use (about 4 faxes received per day), this ink cartridge is already running out of ink. The faxes are faint and hard to read. I expect more from a $34 cartridge.\"]]\u001b[0m\n",
      "\u001b[34minput_ids: [[[101,2025,2069,2003,27286,...,0,0,0,0,0],[101,1045,3856,2023,2039,...,0,0,0,0,0],...,[101,1045,3641,1996,14257,...,0,0,0,0,0],[101,2023,2208,2003,2307,...,0,0,0,0,0]],[[101,1996,28699,2015,2298,...,0,0,0,0,0],[101,1045,2064,1005,1056,...,0,0,0,0,0],...,[101,1045,2001,2200,3407,...,0,0,0,0,0],[101,2023,2003,1037,5667,...,0,0,0,0,0]],...,[[101,2065,2017,2066,3666,...,0,0,0,0,0],[101,2012,2190,2023,2003,...,0,0,0,0,0],...,[101,2035,1996,2774,2006,...,0,0,0,0,0],[101,16215,5332,3729,2003,...,0,0,0,0,0]],[[101,1045,2031,3191,2116,...,0,0,0,0,0],[101,2256,3336,7078,7459,...,0,0,0,0,0],...,[101,2023,2338,3640,2210,...,0,0,0,0,0],[101,2044,2069,1037,3204,...,0,0,0,0,0]]]\u001b[0m\n",
      "\u001b[34mattention_mask: [[[1,1,1,1,1,...,0,0,0,0,0],[1,1,1,1,1,...,0,0,0,0,0],...,[1,1,1,1,1,...,0,0,0,0,0],[1,1,1,1,1,...,0,0,0,0,0]],[[1,1,1,1,1,...,0,0,0,0,0],[1,1,1,1,1,...,0,0,0,0,0],...,[1,1,1,1,1,...,0,0,0,0,0],[1,1,1,1,1,...,0,0,0,0,0]],...,[[1,1,1,1,1,...,0,0,0,0,0],[1,1,1,1,1,...,0,0,0,0,0],...,[1,1,1,1,1,...,0,0,0,0,0],[1,1,1,1,1,...,0,0,0,0,0]],[[1,1,1,1,1,...,0,0,0,0,0],[1,1,1,1,1,...,0,0,0,0,0],...,[1,1,1,1,1,...,0,0,0,0,0],[1,1,1,1,1,...,0,0,0,0,0]]]\u001b[0m\n",
      "\u001b[34mdata_dir ['amazon_polarity.csv', 'entrypoint', 'code']\u001b[0m\n",
      "\u001b[34mself.output_dir ['train', 'test']\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_processor.run(\n",
    "    #job_name=\"preprocessing\", ## 이걸 넣어야 캐시가 작동함, 안그러면 프로세서의 base_job_name 이름뒤에 날짜 시간이 붙어서 캐시 동작 안함\n",
    "    code='preprocessing.py', #소스 디렉토리 안에서 파일 path\n",
    "    source_dir= \"./code\", #현재 파일에서 소스 디렉토리 상대경로 # add processing.py and requirements.txt here\n",
    "    git_config=git_config,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            input_name=\"input-data\",\n",
    "            source=data_path,\n",
    "            destination=os.path.join(proc_prefix, \"input\")\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[       \n",
    "        ProcessingOutput(\n",
    "            output_name=\"output-data\",\n",
    "            source=os.path.join(proc_prefix, \"output\"),\n",
    "            destination=output_path\n",
    "        ),\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"--proc_prefix\", proc_prefix,\n",
    "        \"--split_rate\", \"0.8\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d25f1b63-b084-45ad-927c-80b4c944d44f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sm-bert-ramp/ramp-mlops/preprocessing/data'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!aws s3 sync $output_path ./data/preprocessing --quiet\n",
    "output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e2542-3e59-4fb0-bffe-edf6f8b6e576",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. parameter store에 Processing output 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ae4a02-a24c-470b-81ba-e2179ad33911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Store suceess'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.put_params(key=\"-\".join([prefix, \"PREP-DATA-PATH\"]), value=output_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e436f48-59fb-41d3-80cb-a53768c879a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
