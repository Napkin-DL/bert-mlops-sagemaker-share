{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09065721",
   "metadata": {},
   "source": [
    "# SageMaker Endpoint (Single Model Endpoint)\n",
    "---\n",
    "\n",
    "이제 **SageMaker 모델 호스팅 서비스인 SageMaker 엔드포인트**에 모델을 배포할 준비가 되었습니다. \n",
    "\n",
    "SageMaker 엔드포인트는 REST API를 통해 실시간 추론을 수행할 수 있는 완전 관리형 서비스입니다. 기본적으로 분산 컨테이너로 고가용성, 다중 모델 로딩, A/B 테스트를 위한 인프라 환경(EC2, 로드밸런서, 오토스케일링, 모델 아티팩트 로딩 등)이 사전 구축되어 있기에 몇 줄의 코드만으로 Endpoint가 자동으로 생성되기에, 모델을 프로덕션에 빠르게 배포할 수 있습니다.\n",
    "\n",
    "SageMaker 빌트인 XGBoost를 사용하면 별도의 훈련/추론 스크립트 작성 없이 쉽게 모델을 훈련하고 엔드포인트로 배포할 수 있습니다. 하지만, 여러 가지 요인들로 인해 (예: SHAP 계산을 위한 피쳐 기여값 리턴, 추론값 및 추론 스코어 동시 리턴 등) 커스텀 추론 로직이 필요한 경우, SageMaker 빌트인 XGBoost 대신 SageMaker XGBoost 컨테이너를 사용할 수 있습니다.\n",
    "\n",
    "이 노트북은 SageMaker XGBoost 컨테이너 상에서, 기본적인 추론 스크립트로 모델을 배포하는 법을 아래와 같은 목차로 진행합니다. \n",
    "\n",
    "완료 시간은 **20-30분** 정도 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809dde34-c57d-45e9-b538-5f3c63f74c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3e2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf61ffb1-c09b-4bd1-8aec-6bf591d5a24c",
   "metadata": {},
   "source": [
    "## 1. parameter store 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820e0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from utils.ssm import parameter_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a41fb0-70fb-49c6-a517-4d5603327d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "pm = parameter_store(region)\n",
    "\n",
    "prefix = pm.get_params(key=\"PREFIX\")\n",
    "bucket_name = pm.get_params(key=\"-\".join([prefix, \"BUCKET-NAME\"]))\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c332d20-8a5e-40f3-bd62-40af375e76e5",
   "metadata": {},
   "source": [
    "### Upload model/source artifacts to S3\n",
    "압축한 모델 아티팩트를 Amazon S3로 복사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f30ad-ad14-4333-8378-6db69106a4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = pm.get_params(key=\"-\".join([prefix, \"MODEL-PATH\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51977cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf model && mkdir -p model\n",
    "!aws s3 cp {model_path} ./ \n",
    "!mv model.tar.gz ./model/\n",
    "# !cd model && tar -xvf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c68ee3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 1. Create Model Serving Script\n",
    "\n",
    "---\n",
    "\n",
    "아래 코드 셀은 src 디렉토리에 SageMaker 추론 스크립트를 저장합니다.\n",
    "\n",
    "#### Option 1.\n",
    "- `model_fn(model_dir)`: S3의 `model_dir`에 저장된 모델 아티팩트를 로드합니다.\n",
    "- `input_fn(request_body, content_type)`: 입력 데이터를 전처리합니다. `content_type`은 입력 데이터 종류에 따라 다양하게 처리 가능합니다. (예: `application/x-npy`, `application/json`, `application/csv`등)\n",
    "- `predict_fn(input_object, model)`: `input_fn(...)`을 통해 들어온 데이터에 대해 추론을 수행합니다.\n",
    "- `output_fn(prediction, accept_type)`: `predict_fn(...)`에서 받은 추론 결과를 후처리를 거쳐 프론트엔드로 전송합니다.\n",
    "\n",
    "#### Option 2.\n",
    "- `model_fn(model_dir)`: S3의 model_dir에 저장된 모델 아티팩트를 로드합니다.\n",
    "- `transform_fn(model, request_body, content_type, accept_type)`: `input_fn(...), predict_fn(...), output_fn(...)`을 `transform_fn(...)`으로 통합할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79db23-e4f6-4327-bf6a-d1c2df396fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile code/inference.py\n",
    "# import os\n",
    "# import json\n",
    "# import time\n",
    "# import torch\n",
    "# import tarfile\n",
    "# import argparse\n",
    "# import numpy as np\n",
    "# from io import BytesIO\n",
    "# from datasets import load_from_disk\n",
    "# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "# def model_fn(model_dir):\n",
    "#     \"\"\"\n",
    "#     Deserialize and return fitted model.\n",
    "#     \"\"\"\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#         model_dir,\n",
    "#         num_labels=2\n",
    "#     )\n",
    "#     return (tokenizer, model)\n",
    "                     \n",
    "\n",
    "# def input_fn(request_body, request_content_type):\n",
    "#     \"\"\"\n",
    "#     The SageMaker XGBoost model server receives the request data body and the content type,\n",
    "#     and invokes the `input_fn`.\n",
    "#     Return a DMatrix (an object that can be passed to predict_fn).\n",
    "#     \"\"\"\n",
    "#     print(\"Content type: \", request_content_type)\n",
    "#     if request_content_type == \"application/x-npy\":        \n",
    "#         stream = BytesIO(request_body)\n",
    "#         return stream.getvalue().decode()\n",
    "#     elif request_content_type == \"text/csv\":\n",
    "#         return request_body.rstrip(\"\\n\")\n",
    "#     else:\n",
    "#         raise ValueError(\n",
    "#             \"Content type {} is not supported.\".format(request_content_type)\n",
    "#         )\n",
    "        \n",
    "\n",
    "# def predict_fn(return_input_fn, return_model_fn):\n",
    "#     \"\"\"\n",
    "#     SageMaker XGBoost model server invokes `predict_fn` on the return value of `input_fn`.\n",
    "\n",
    "#     Return a two-dimensional NumPy array (predictions and scores)\n",
    "#     \"\"\"\n",
    "#     start_time = time.time()\n",
    "    \n",
    "    \n",
    "#     print(f\"******************** return_input_fn : {return_input_fn}\")\n",
    "    \n",
    "    \n",
    "#     tokenizer, model = return_model_fn\n",
    "#     encoded_input = tokenizer(return_input_fn, return_tensors='pt')\n",
    "    \n",
    "#     output = model(**encoded_input)\n",
    "#     pred = torch.argmax(output.logits, dim=1)\n",
    "    \n",
    "#     print(f\"******************** pred : {pred}\")\n",
    "    \n",
    "#     print(\"--- Inference time: %s secs ---\" % (time.time() - start_time))\n",
    "#     return pred\n",
    "\n",
    "\n",
    "# def output_fn(predictions, content_type=\"application/json\"):\n",
    "#     \"\"\"\n",
    "#     After invoking predict_fn, the model server invokes `output_fn`.\n",
    "#     \"\"\"\n",
    "#     if content_type == \"text/csv\":\n",
    "#         return predictions.tolist()[0]\n",
    "#     elif content_type == \"application/json\":\n",
    "#         outputs = json.dumps({'pred': predictions.tolist()[0]})        \n",
    "        \n",
    "#         return outputs\n",
    "#     else:\n",
    "#         raise ValueError(\"Content type {} is not supported.\".format(content_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c2412",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 2. Deploy a trained model from Amazon S3\n",
    "---\n",
    "\n",
    "SageMaker API의 `Model` 클래스는 훈련한 모델을 서빙하기 위한 모델 아티팩트와 도커 이미지를 정의합니다. \n",
    "`Model` 클래스 인스턴스 호출 시 AWS에서 사전 빌드한 도커 이미지 URL을 직접 가져올 수도 있지만, Model의 자식 클래스로(예: `XGBoostModel`, `TensorFlowModel`) 초기화하면 파라메터에 버전만 지정하는 것만으로 편리하게 추론을 수행하는 환경을 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471eefc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2.1. Deploy to Local Environment: PytorchModel class\n",
    "\n",
    "SageMaker 호스팅 엔드포인트로 배포하기 전에 로컬 모드 엔드포인트로 배포할 수 있습니다. 로컬 모드는 현재 개발 중인 환경에서 도커 컨테이너를 실행하여 SageMaker 프로세싱/훈련/추론 작업을 에뮬레이트할 수 있습니다. 추론 작업의 경우는 Amazon ECR의 딥러닝 프레임워크 기반 추론 컨테이너를 로컬로 가져오고(docker pull) 컨테이너를 실행하여(docker run) 모델 서버를 시작합니다.\n",
    "\n",
    "\n",
    "```python\n",
    "local_model_path = f'{os.getcwd()}/model'\n",
    "ecr_uri = xgb_image_uri\n",
    "\n",
    "# 도커 컨테이너 구동\n",
    "!docker run --name xgb -itd -p 8080:8080 -v {local_model_path}:/opt/ml/model {ecr_uri} serve\n",
    "\n",
    "# 실시간 호출 테스트 \n",
    "!curl -X POST -H 'Content-Type: application/json' localhost:8080/invocations -d ...\n",
    "\n",
    "# 도커 컨테이너 중지 및 삭제    \n",
    "!docker stop xgb\n",
    "!docker rm xgb\n",
    "```\n",
    "\n",
    "참고로 SageMaker SDK에서 `deploy(...)` 메소드로 엔드포인트 배포 시, 인스턴스 타입을 local 이나 local_gpu로 지정하면 위의 과정을 자동으로 수행할 수 있습니다.\n",
    "\n",
    "```python\n",
    "# 로컬 엔드포인트 배포\n",
    "local_predictor = local_model.deploy(initial_instance_count=1, instance_type=\"local\")\n",
    "\n",
    "# 실시간 호출 테스트 \n",
    "local_predictor.predict(...)\n",
    "\n",
    "# 로컬 엔드포인트 삭제 (도커 컨테이너 중지 및 삭제)\n",
    "local_predictor.delete_endpoint()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dafaf0",
   "metadata": {},
   "source": [
    "아래 코드를 보시면 아시겠지만, 지속적으로 업데이트되는 파이썬 버전&프레임워크 버전&트랜스포머 버전에 쉽게 대응할 수 있습니다. AWS에서 관리하고 있는 딥러닝 컨테이너(DLC) 목록을 아래 주소에서 확인해 보세요.\n",
    "- https://github.com/aws/deep-learning-containers/blob/master/available_images.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a1bd9",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafcb929-0cce-4579-a26f-e85207aef46d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type='local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22630e10-578c-46ca-ab49-c392bb334e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# source_dir=f\"file://{Path.cwd()}/src\"\n",
    "\n",
    "if instance_type in ['local', 'local_gpu']:\n",
    "    from sagemaker.local import LocalSession\n",
    "    \n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    model_data=f\"file://{Path.cwd()}/model/model.tar.gz\"\n",
    "else:\n",
    "    sagemaker_session = sagemaker.session.Session()\n",
    "    model_data=model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfcb78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    source_dir=\"code\",\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    framework_version='2.0.0',\n",
    "    py_version='py310',\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364bb6a0",
   "metadata": {},
   "source": [
    "### Create Endpoint\n",
    "\n",
    "SageMaker SDK는 `deploy(...)` 메소드를 호출 시, `create-endpoint-config`와 `create-endpoint`를 같이 수행합니다. 좀 더 세분화된 파라메터 조정을 원하면 AWS CLI나 boto3 SDK client 활용을 권장 드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2abd0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pytorch_predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd036cc",
   "metadata": {},
   "source": [
    "### Check Docker\n",
    "\n",
    "모델 서빙을 위한 도커 컨테이너가 구동되고 있음을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fd6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78f3f4",
   "metadata": {},
   "source": [
    "### Prediction - boto3 SDK & application/x-npy\n",
    "\n",
    "위의 코드 셀처럼 SageMaker SDK의 `predict(...)` 메소드로 추론을 수행할 수도 있지만, 이번에는 boto3의 `invoke_endpoint(...)` 메소드로 추론을 수행해 보겠습니다.\n",
    "Boto3는 서비스 레벨의 저수준(low-level) SDK로, ML 실험에 초점을 맞춰 일부 기능들이 추상화된 고수준(high-level) SDK인 SageMaker SDK와 달리 SageMaker API를 완벽하게 제어할 수 있습으며, 프로덕션 및 자동화 작업에 적합합니다.\n",
    "\n",
    "[Note] `invoke_endpoint(...)` 호출을 위한 런타임 클라이언트 인스턴스 생성 시, 로컬 배포 모드에서는`sagemaker.local.LocalSagemakerRuntimeClient(...)`를 호출해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518f960-e135-479f-8c7c-c673e2fe347e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = \"This book offers useful, practical guidelines to support nonprofit managers in their efforts to maximize the effectiveness with which their organizations use their valuable resources.Nonprofit managers and leaders must advance their mission while balancing the agendas of trustees, funders, staff, and government. In this context, this group of expert authors explores core operating decisions that face all organizations and provides solutions that are unique to nonprofits of any size. Their chapters cover such key decisions as pricing of services, compensation of staff, outsourcing, fundraising expenditures, and investment and disbursement of funds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d16634c-cd98-45b5-89c8-b4ce217b6191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "if instance_type in ['local', 'local_gpu']:\n",
    "    import sagemaker\n",
    "    runtime_client = sagemaker.local.LocalSagemakerRuntimeClient()\n",
    "    endpoint_name = pytorch_model.endpoint_name\n",
    "else:\n",
    "    import boto3\n",
    "    runtime_client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af12020-1fa5-42e3-9e83-876b085eca7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='application/x-npy',\n",
    "    Accept='application/json',\n",
    "    Body=payload.encode()\n",
    ")\n",
    "print(f\"******************* Prediction : {json.loads(response['Body'].read().decode())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d180d",
   "metadata": {},
   "source": [
    "### Prediction - boto3 SDK & text/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66564cf-9a4c-4186-8284-c74f5773447f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from io import StringIO\n",
    "csv_file = io.StringIO()\n",
    "payload = test_sentence\n",
    "print(f\"payload : {payload}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b394895-152f-4812-aeb1-14dc0a547811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='text/csv',\n",
    "    Accept='application/json',\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "print(f\"******************* Prediction : {json.loads(response['Body'].read().decode())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadddacf",
   "metadata": {},
   "source": [
    "### Local Mode Endpoint Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca908e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pytorch_predictor.delete_endpoint()\n",
    "pytorch_model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ba349",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2.2. Deploy to Hosting Instance\n",
    "\n",
    "로컬 모드에서 충분히 디버깅했으면 실제 호스팅 인스턴스로 배포할 차례입니다. 코드는 거의 동일하며, `instance_type`만 다르다는 점을 주목해 주세요! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a801b1-e99c-42b2-9cd1-155b683768ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type='ml.m5.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b56f76-36c7-4224-8957-e6dd3ed0979c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# source_dir=f\"file://{Path.cwd()}/src\"\n",
    "\n",
    "if instance_type in ['local', 'local_gpu']:\n",
    "    from sagemaker.local import LocalSession\n",
    "    \n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    model_data=f\"file://{Path.cwd()}/model/model.tar.gz\"\n",
    "else:\n",
    "    sagemaker_session = sagemaker.session.Session()\n",
    "    model_data=model_path\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bcdcfe",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae35c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    source_dir=\"code\",\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    framework_version='2.0.0',\n",
    "    py_version='py310',\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd632e",
   "metadata": {},
   "source": [
    "### Create Endpoint\n",
    "\n",
    "SageMaker SDK는 `deploy(...)` 메소드를 호출 시, `create-endpoint-config`와 `create-endpoint`를 같이 수행합니다. 좀 더 세분화된 파라메터 조정을 원하면 AWS CLI나 boto3 SDK client 활용을 권장 드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad942a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import strftime\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "\n",
    "create_date = strftime(\"%m%d-%H%M%s\")\n",
    "endpoint_name=f'finetune-{model_name}-{create_date}'\n",
    "\n",
    "pytorch_predictor = pytorch_model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type, \n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f911c60",
   "metadata": {},
   "source": [
    "### Wait for the endpoint jobs to complete\n",
    "\n",
    "엔드포인트가 생성될 때까지 기다립니다. 엔드포인트가 가리키는 호스팅 리소스를 프로비저닝하는 데에 몇 분의 시간이 소요됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d680ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "def make_endpoint_link(region, endpoint_name, endpoint_task):\n",
    "    endpoint_link = f'<b><a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/endpoints/{endpoint_name}\">{endpoint_task} Review Endpoint</a></b>'   \n",
    "    return endpoint_link \n",
    "        \n",
    "endpoint_link = make_endpoint_link(region, pytorch_predictor.endpoint_name, '[Deploy model from S3]')\n",
    "display(HTML(endpoint_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecba5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session.wait_for_endpoint(pytorch_predictor.endpoint_name, poll=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00697f",
   "metadata": {},
   "source": [
    "### Prediction - SageMaker SDK & text/csv\n",
    "샘플 데이터에 대해 추론을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d32365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer, NumpySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "pytorch_predictor.serializer = CSVSerializer()\n",
    "pytorch_predictor.deserializer = JSONDeserializer() \n",
    "\n",
    "outputs = pytorch_predictor.predict(test_sentence)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f9424",
   "metadata": {},
   "source": [
    "### Prediction - boto3 SDK & application/x-npy\n",
    "\n",
    "위의 코드 셀처럼 SageMaker SDK의 `predict(...)` 메소드로 추론을 수행할 수도 있지만, 이번에는 boto3의 `invoke_endpoint(...)` 메소드로 추론을 수행해 보겠습니다.\n",
    "Boto3는 서비스 레벨의 저수준(low-level) SDK로, ML 실험에 초점을 맞춰 일부 기능들이 추상화된 고수준(high-level) SDK인 SageMaker SDK와 달리 SageMaker API를 완벽하게 제어할 수 있습으며, 프로덕션 및 자동화 작업에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c472196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "endpoint_name = pytorch_model.endpoint_name\n",
    "payload = test_sentence.encode()\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='application/x-npy',\n",
    "    Accept='application/json',\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read().decode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dbfcb",
   "metadata": {},
   "source": [
    "### Prediction - boto3 SDK & text/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d430cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = test_sentence\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='text/csv',\n",
    "    Accept='application/json',\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read().decode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84cb564",
   "metadata": {},
   "source": [
    "### (Optional) Endpoint Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_predictor.delete_endpoint()\n",
    "# pytorch_model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922068bd-fc3b-4bb2-8dbe-c93d95f2caf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f5a19-986a-4d36-a085-ad7664acd525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
